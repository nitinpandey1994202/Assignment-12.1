QUESTION-
1) Explain the need of Flume.
2) Explain the working of Flume and its components in brief.

Answer:-
1)Basically flume is-
Apache Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of 
streaming data into the Hadoop Distributed File System (HDFS). It has a simple and flexible architecture based on streaming data flows,
and is robust and fault tolerant with tunable reliability mechanisms for failover and recovery.

Need of flume-
1) with the help of flume we can store the data in to any of the centralized stores (HBase, HDFS).

2) When the rate of incoming data exceeds the rate at which data can be written to the destination(where the data has to store), 
Flume acts as a mediator between data producers and the centralized stores and provides a steady flow of data between them.
it acts like controllable device. 

3)Flume provides the feature of contextual routing.

4)The transactions in Flume are channel-based where two transactions (one sender and one receiver) are maintained for each message. 
It guarantees reliable message delivery.

5)Flume is reliable, fault tolerant, scalable, manageable, and personalized.

2)
Apache Flume is a tool/service/data ingestion mechanism for collecting aggregating and transporting large amounts of streaming data 
such as log files, events (etc...) from various sources to a centralized data store.
Flume is a highly reliable, distributed, and configurable tool. It is principally designed to copy streaming data (log data)
from various web servers to HDFS.
 
 COMPONENTS OF FLUME:-
1) Flume Event:-
An event is the basic unit of the data transported inside Flume.
It contains a payload of byte array that is to be transported from the source to the destination accompanied by optional headers.

2)Flume Agent:-
An agent is an independent daemon process (JVM) in Flume. It receives the data (events) from clients or other agents and forwards 
it to its next destination (sink or agent). Flume may have more than one agent.

3)Source:-
A source is the component of an Agent which receives data from the data generators and transfers it to one or more channels in 
the form of Flume events.
Example − Avro source, Thrift source, twitter 1% source etc.

4)Channel
A channel is a transient store which receives the events from the source and buffers 
them till they are consumed by sinks. It acts as a bridge between the sources and the sinks.
Example − JDBC channel, File system channel, Memory channel, etc.

5)Sink
A sink stores the data into centralized stores like HBase and HDFS. It consumes the data (events) from the channels and delivers it to 
the destination. The destination of the sink might be another agent or the central stores.

Example − HDFS sink

ADDITIONAL COMPONENT OF FLUME AGENT:-
1)Interceptors
Interceptors are used to alter/inspect flume events which are transferred between source and channel.

     1)Channel Selectors
These are used to determine which channel is to be opted to transfer the data in case of multiple channels. There are two types of channel selectors −

     1)Default channel selectors − These are also known as replicating channel selectors they replicates all the events in each channel.

     2)Multiplexing channel selectors − These decides the channel to send an event based on the address in the header of that event.
     
2)Sink Processors
These are used to invoke a particular sink from the selected group of sinks. These are used to create failover paths for your sinks or
load balance events across multiple sinks from a channel.
